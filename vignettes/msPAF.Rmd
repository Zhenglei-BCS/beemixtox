---
title: "msPAF"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{msPAF}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval=F
)
```

```{r setup}
library(beemixtox)
```

## Background

PAF(potentially affected fraction) definition: inverse way of $HC_p$. Given a concentration, find out $p$. In general, PAF can be considered an indicator for "toxic pressure" on the ecosystems.

The quantile (or PAF) for each species was calculated approximately by $\frac{i-0.5}{n}$, where $i$ is the rank of the sensitivity, $i=1$, the most sensitive and $n$ the least sensitive species.

$\alpha$ intercept, $\beta$ slope.


if assuming log-logistic distribution.

$$PAF(x)=1/(1+\exp((\alpha-x)/\beta))$$
$\alpha$ is the mean value of the log-logistic distribution, $\beta$ is the scale parameter. $x$ is log of the concentration. $\beta=\sigma\times\sqrt{3}/\pi$

Rewriting above into $x=\alpha-\beta\log(\frac{1-PAF}{PAF})$, when $x=HC_5$ then $PAF=0.05$


The current method to calculate the $HC_5$ and $HC_{50}$ makes use of the log-normal
species sensitivity distribution (Aldenberg and Jaworska, 2000) instead of a log-logistic
distribution. The differences between these two distributions are small. *The advantage of analytic tractability of the logistic distribution is outweighed by the
statistical advantage of using the log-normal distribution. (Personally I don't understand this sentence)*

Assuming log-normal

$$\log(HC_p)=x-k\cdot s$$

where $x$ is the mean of the log-transformed data, $k$ is the extrapolation constant depending on protection level and sample size (Aldenberg and Jaworska, 2000), $s$ is the standard deviation of log-transformed data. 

### msPAF (multisubstance PAF)

An aggregation protocol has been designed to aggregate single-substance PAF
values to a single overall term of ecological risk of a mixture. The protocol is based
on application of two toxicological concepts: concentration addition (termed Simple
Similar Action by Plackett and Hewlett, 1952) and response addition (termed Independent
Joint Action by Plackett and Hewlett, 1952). The concepts are summarized
and the associated rules of calculus are introduced below.


### Concentration Addition 

The toxicological concept of concentration addition has been defined for compounds
that have the same toxic mode of action and that show no toxicological interactions
(Plackett and Hewlett, 1952). This concept is usually applied to characterize the
response observed in single-species toxicity tests in which the response to several
compounds with the same mode of action is considered. By definition, the joint
effect of such compound mixtures can be calculated using (relative) concentration
addition rules of calculus (Plackett and Hewlett, 1952; Deneer et al., 1988a; Altenburger
et al., 2000; Chapter 15).

Neutral hydrophobic organic compounds are believed to act by a similar, nonspecific
toxic mode of action called *narcosis*, which every hydrophobic compound
can exert, but which can be masked by another, more specific toxic effect (Könemann,
1981). In other words, almost every hydrophobic chemical exerts at least a
narcotic, nonspecific toxicity that contributes to the joint toxicity of mixtures, and
this is often referred to as baseline toxicity (Verhaar et al., 1992; 1995). At the species level, toxicity equivalence factors (TEFs) have been used to express the toxicity of one compound as a fraction of another compound with the same toxic mode of
action. Transfer of the TEF principle to SSDs by scaling compounds in a similar
way results in so-called hazard units (Box 16.1). For compounds with the same toxic
mode of action, a single SSD can be derived using (relative) concentration addition
quantified by hazard units, representing the separate compounds and any mixture of
these compounds. It is assumed that the toxic mode of action in this case applies to
the SSD comprising all relevant species.

For compounds with a non-narcotic toxic mode of action, the situation is more
complicated. Some species experience the same type of effect due to specific interactions at targets sites that only occur in a fraction of the species, and other species only experience narcosis, due to lack of specific target sites for the compound. This holds, for example, for organophosphate (OP) biocides. Each OP biocide acts by
acetylcholinesterase inhibition, and thus all compounds in this group can be seen as
fractions of each other provided that the exposed organisms have a receptor for this
compound. For those organisms, concentration addition rules of calculus should be
applied for the specifically working OP biocides. However, species that lack the
target receptor are not sensitive for OP exposure, and will only experience narcotic
baseline toxicity. This means that concentration addition for specific toxic modes of
action is only appropriate within a single SSD if the SSD consists of species having
the specific receptor. For the organisms without the receptor, it may be more useful
to consider narcotic concentration addition. Moreover, compounds can be more toxic
than expected from baseline toxicity, although the exposed species do not have the
receptor for a compound. These complications are further elaborated in Chapter 22.

As a method to aggregate several PAF values from SSDs for compounds with
a similar toxic mode of action to a single msPAF term, it is proposed to apply
concentration addition rules. The cumulative density function (CDF) of (log) toxicity
data is regarded as similar to the log-dose–response curve for single species. This
is illustrated in Box 16.1 for NOECs, but the principle can be applied to other test
endpoints as well.

**Toxicity Data**

1. Obtain NOECs for each compound.
2. mg/L for aquatic organisms, mg/L soil pore water for soil organisms.
3. scale into dimensionless HU (hazard units), with 1 HU defined as the concentration where the NOEC is exceeded for 50% of all species tessted. 
 $$\bar NOEC_i^j=\frac{NOEC_i^j}{\bar x_i}$$
 where, $\bar NOEC_i^j$ is the scaled NOECs in HUs ($\mu$g/L/$\mu$g/L). $\bar x_i$ the median NOEC for substance $i$. $i=1, ..., n$, and species $j$ from $1,...,m$.

4. This is analogous to toxic unit (TU) scaling for a single species where 1 TU is the concentration causing 50% effect. 
5. Fitting SSD with either log-logistic model or log-normal in HUs for each compound. Alternatively, it can be found by shifting the CDF of log NOECs by subtracting log($\bar x_i$). 
6. Concentration addition in the context of SSDs implies that **SSDs have
similar variance** for compounds with the same toxic mode of action. The hypothesis is $H_0: \sigma_A=\sigma_B$. If they differ significantly, no rules of calculus
have as yet been developed to take divergence in variance (equivalent to
slope divergence in the classical concentration addition literature; see
Bliss, 1939; Plackett and Hewlett, 1952; De March, 1987) into account.
If they do not differ, this does not prove concentration additivity; it can
also be a result of small sample sizes.

**Exposure Data**

7. For each compound the exposure conentration is recalculated to HU.

**PAF Calculations for Concentration Addition (CA)**
8. The $msPAF_{CA}$ is read from the CDF by HU addition (non-log-transformed)
for a single toxic mode of action (TMoA):

$$HU_{TMoA}=\sum_i HU$$
9. If the log toxicity data are fitted to a logistic distribution, the PAF for each compound is given by 

$$PAF_i=\frac{1}{1+e^{-(x-\alpha)/\beta}}$$

with $\alpha$ mean of the log toxicity data and $\beta=\sigma\cdot\sqrt 3/\pi$, $\sigma$ the sd and $x$ the log of the exposure concentration.

10. After recalculation of all compound concentrations to HUs, $\alpha=0$ by definition and $x$ is given by the sum of $HU_{TMoA}$ of all compounds with the same toxic mode of action. The $\beta$ is averaged over the compounds or, alternatively, can be derived from a database analysis for the toxic mode of action.

11. the $msPAF_{CA}$ for a group of substances
with the same toxic mode of action is calculated as

$$PAF_{TMoA}=\frac{1}{1+e^{-\log(\sum HU_{TMoA}))/\beta_{TMoA}}}$$

### Response Addition

For compounds that have different modes of action, and that do not interact at the
target site of toxic action, mixture toxicity can be described by the term
response addition (RA), initially referred to as Independent (Joint) Action (Bliss, 1939; Plackett and Hewlett, 1952). This concept is usually applied to characterize the response observed in single-species toxicity tests for chemicals with dissimilar modes of action. A correlation of sensitivities to the different compounds is absent.

**PAF Calculations for Response Addition**

- The combination effect for compounds with different modes of action is
calculated analogous to the probability of two nonexcluding processes
(Hewlett and Plackett, 1979), where a species is affected by compound A
and/or B:

$$P(A \cup B) = P(A)+P(B)-P(A\cap B)$$
- For $P(A\cap B)$ These are related to the covariation of sensitivities, denoted by
r.

- When $r=0$, then $P(A\cap B)=P(A)\cdot P(B)$, which leads to 

$$PAF_{RA}=P(A)+P(B)-P(A)\cdot P(B)
$$
- To simplify for  multiple compound mixtures. The nonaffected fraction, is
introduced. If $Q_A=1-PAF_A$, and $Q_B=1-PAF_B$, the nonaffected fraction
of the mixture of A and B is a part of $Q_A$ of $Q_B$. 

$$Q_{AB}=Q_A\cdot Q_B
$$

- Then msPAF is given by:
$$
PAF_{RA}=1-Q_{AB}=1-(1-PAF_A)(1-PAF_B)
$$
- For more compounds

$$
PAF_{RA}=1-\Pi_i(1-PAF_i)
$$
### Aggregation to msPAF

The substances comprising the mixture are grouped in three different
types: (a) one or more groups of compounds in which there is within-group concentration
addition, (b) groups of compounds distinguished by between-group
response addition, and (c) remaining compounds with a toxic mode of action that
is unique for the given mixture. Calculation of overall msPAF of all the compounds
from the three different types a to c then proceeds in the following order:


1. SSDs are calculated for each compound, yielding as many (single-substance)
SSDs as there are compounds on the list.
2. Concentration addition (according to Box 16.1) is applied to each group
of compounds with the same toxic mode of action, to aggregate single
PAFs for compounds of type a, showing within-group concentration addition.
This yields msPAF values based on concentration addition ($msPAF_{CA}$)
for as many modes of action as are distinguished in the mixture.
3. Response addition according to Box 16.2 is applied to the $msPAF_{CA}$ values
obtained in step 2 with the remaining single PAF values (aggregating over
types a to c).


## Toxic Pressure Modelling

$$\mbox{Toxic Pressure} = \Pr(C_w>EC_{50}) = \int_{-\infty}^{\infty}pdf(zC_w)\times CDF(zEC_{50})dz$$
with $z(C_w)=\frac{\log C_w-av(\log EC_{50})}{sd(\log EC_{50})}$ and 

$z(EC_{50})=\frac{\log EC_{50}-av(\log EC_{50})}{sd(\log EC_{50})}$, where $pdf(zC_w)$ and $CDF(zEC_{50})$ represent the pdf of toxicologically standardized exposure concentrations (in water) and the cdf of toxicologically standardized acute $EC_{50}$ values. 

Values of $sd(\log EC_{50}$ are often not
known with great precision for many chemicals, because of
insufficient numbers of experimental toxicity data (Posthuma
et al. 2019b). Following the practice of Posthuma et al. (2019b),
we assigned the value 0.7 to across‐species standard
deviations of all individual chemicals, for the purpose of toxic
pressure calculation.

## Question from Ismael

b.	I calculated the msPAF according to the equation, and checked if the sum of the individual PAF values (calculated for each chemical individually) is equal to the calculated msPAF for the mixture. In fact the sum(PAF) underestimate the msPAF and is dependent on n components. I think it is logical because the equation involves operations in log scales and CDFs, so that msPAF(1+2) is not equal to PAF1 + PAF2. 
c.	The question is: How can I calculate the fractional contribution of each chemical X to the msPAF? Do you think it is possible? Or may there be a magical mathematical approximation to solve this problem?

**My thoughts**

similar to the frequent practice of water quality assessment for mixtures by *linearly summed risk quotients over compounds*, whereby numerical values estimated
with the simplified and the original (more complex) model are similar.


Relative rankings of the contributions of chemicals to those impacts on a regional scale
were derived in 2 steps. In the first step, *a relative toxicity score for each compound* in a subset of samples (Europe or a specific example river basin) was determined as the product of the *mean compound toxic pressure* in the set and *the ratio between the non-zero values for that compound and the non-zero values for the mixtures*. Those represent the magnitude and the relative contribution and frequency of increased compound pressures to total mixture pressures. All scores were then relatively ranked using the lowest-ranking compound as the baseline (defined as “1”).

A PAF value relates to the concept of protective
benchmarks, if those are derived from an SSD of chronic
NOECs, such as the hazardous concentration for 5% of the
species (HC5). Higher toxic pressures imply higher fractions of
species affected for the studied acute or chronic endpoint.

sufficient protection relates to PAF-NOECmax=
msPAF-NOECmax=0.05, which is in regulatory terms considered
to protect 95% of the species against adverse effects.


The observed Pareto-type
(skewed) distributions imply that relatively few sites are
characterized by relatively high chronic toxic pressures.

toxic pressure data aggregated over an area and over time.


## Results

```{r}
data("Data.AggBySiteID.2")
# The values that are below LOQ are set to 0 ug/L
Data.AggBySiteID.3 = Data.AggBySiteID.2
Data.AggBySiteID.3$resultMaximumValue[Data.AggBySiteID.3$AboveLOQ=="FALSE"] = 0
Data.AggBySiteID.3$resultMeanValue[Data.AggBySiteID.3$AboveLOQ=="FALSE"] = 0

# New name to be able to restart for running other options
Data.AggBySiteID.3a = Data.AggBySiteID.3
```



```{r}
# Remove priority polluants entries and metals
Exclusion.CAS = "Excluded_Priority & Metals"
Data.AggBySiteID.3a = Data.AggBySiteID.3a[!Data.AggBySiteID.3a$CAS%in%c(CAS.Metals$CAS,CAS.Priority$CAS),]
```


```{r}
#########################################################################################
# Recalculate Measured and detected chemicals based on the exclussions

# How many determinads measured per station and Year?
#variable to keep
var = c("monitoringSiteIdentifier","CAS","phenomenonTimeReferenceYear")
DataForNChem.1 = Data.AggBySiteID.3a[,names(Data.AggBySiteID.3a)%in%c(var)]
## Note by ZG: Could directly take the column names 
## DataForNChem.2 <- Data.AggBySiteID.3a[,c("monitoringSiteIdentifier","CAS","phenomenonTimeReferenceYear")]
#measured chemicals

```


```{r ismael-aggregate,eval=F}
measured.chem.1 = aggregate(CAS ~ monitoringSiteIdentifier + phenomenonTimeReferenceYear, data =DataForNChem.1, length) ## Get number of CAS measured for each site and year. 
#detected chem
detected.chem.1 = aggregate(CAS ~ monitoringSiteIdentifier + phenomenonTimeReferenceYear, data =DataForNChem.1[Data.AggBySiteID.3a$resultMaximumValue!=0,], length)

#Subset data for these selection of Station Year combinations
measured.chem.1$Site.Year = paste(measured.chem.1$monitoringSiteIdentifier,measured.chem.1$phenomenonTimeReferenceYear, sep=".")
detected.chem.1$Site.Year = paste(detected.chem.1$monitoringSiteIdentifier,detected.chem.1$phenomenonTimeReferenceYear, sep=".")

# Merge measured & detected
measured.chem.1 = merge(measured.chem.1, detected.chem.1, by=c("monitoringSiteIdentifier","phenomenonTimeReferenceYear","Site.Year"), all.x = T)
names(measured.chem.1)[c(4,5)] = c("N.Measured.1", "N.Detected.1")
measured.chem.1$N.Detected.1[is.na(measured.chem.1$N.Detected.1)] = 0 #There are some NAs that needs attention, may be are samples where all is non-detected?
measured.chem.1$Ratio.MD.1 = measured.chem.1$N.Detected.1/measured.chem.1$N.Measured.1
summary(measured.chem.1)

Data.AggBySiteID.3a = merge(Data.AggBySiteID.3a,measured.chem.1, by=c("monitoringSiteIdentifier","phenomenonTimeReferenceYear","Site.Year"), all.x = T)
measured.chem.All = merge(measured.chem, measured.chem.1, by=c("monitoringSiteIdentifier","phenomenonTimeReferenceYear","Site.Year"), all.x = T)
# No measure, no detection to 0
measured.chem.All$N.Measured.1[is.na(measured.chem.All$N.Measured.1)] = 0
measured.chem.All$N.Detected.1[is.na(measured.chem.All$N.Detected.1)] = 0
summary(measured.chem.All)
hist(measured.chem.All$N.Measured.1)
hist(measured.chem.All$N.Detected.1)
table(measured.chem.All$N.Measured.1>10) # 9407 combinations measuring 10 or more ==> 9602
table(measured.chem.All$N.Detected.1>10) # 2135 combinations detecting 10 or more ==> 2289
# Merge with SSD info (mu.sig) by CAS numner, note each CAS has one SSD info!
Data.AggBySiteID.3a = merge(Data.AggBySiteID.3a, Data.SSD.1[,names(Data.SSD.1)%in%c("CAS.","X10LogSSDMedianConcentration.ug.L..MuAcute.EC50","X10LogSSDMedianConcentration.ug.L..MuChronic.NOEC", "X10LogSSDSlope.ug.L..SigmaAcute.EC50","X10LogSSDSlope.ug.L..SigmaChronic.NOEC")], by.x = "CAS", by.y="CAS.")
names(Data.AggBySiteID.3a)[(16:19)] = c("SSDLOG10.Mu.Acute.EC50", "SSDLOG10.Sigma.Acute.EC50", "SSDLOG10.Mu.chronic.NOEC","SSDLOG10.Sigma.chronic.NOEC")
```


```{r}
tmp <- Data.AggBySiteID.3a %>% group_by(monitoringSiteIdentifier,phenomenonTimeReferenceYear) %>% summarise(Nmeasured=length(CAS),Ndetected=sum(resultMaximumValue>0),Ratio.MD=Ndetected/Nmeasured) ## Ratio is detection rate from all measured. 
# Merge
Data.AggBySiteID.3a <- left_join(Data.AggBySiteID.3a,tmp)


### check there is no NAs
summary(Data.AggBySiteID.3a$resultMaximumValue)
summary(Data.AggBySiteID.3a$resultMeanValue)
ssdInfo <- Data.SSD.1[,c("CAS.","X10LogSSDMedianConcentration.ug.L..MuAcute.EC50","X10LogSSDMedianConcentration.ug.L..MuChronic.NOEC", "X10LogSSDSlope.ug.L..SigmaAcute.EC50","X10LogSSDSlope.ug.L..SigmaChronic.NOEC")] %>% mutate(CAS.=as.character(CAS.))
Data.AggBySiteID.3a <- left_join(Data.AggBySiteID.3a,ssdInfo,by=c("CAS"="CAS."))
dim(Data.AggBySiteID.3a) ## [1] 545641     19

names(Data.AggBySiteID.3a)[(16:19)] = c("SSDLOG10.Mu.Acute.EC50", "SSDLOG10.Mu.chronic.NOEC", "SSDLOG10.Sigma.Acute.EC50","SSDLOG10.Sigma.chronic.NOEC")
```


- From here real calculation starts. 

```{r}
# Calculate PAF by row.
# Equivalent to excel NORMDIST(log10[sumHU],0,0.7,1) is pnorm(log10(Sum(HU),0,07,log=F)
# Carefull because Mu and sigma are given in log10 monitoring data is given in linear scale
# It is necessary to backtransform Mu values to linear scale!?

#Hazard.Index to the midpoint SSD by chem (reference to the HC05)
#Hazard.Index to the HC05 SSD by chem
# Taken from: https://edild.github.io/ssd/
# Will use compoud-specific slopes. Assuming 0.7 SSD slope is quite worst case (as how the data comes out)

#Compute HC05 by chemical ############################################################################
#The mu and sig parameters are given in log10 units!
Data.AggBySiteID.3a$HC50.Acute = 10^qnorm(0.5,Data.AggBySiteID.3a$SSDLOG10.Mu.Acute.EC50, Data.AggBySiteID.3a$SSDLOG10.Sigma.Acute.EC50)
Data.AggBySiteID.3a$HC05.Chronic = 10^qnorm(0.05,Data.AggBySiteID.3a$SSDLOG10.Mu.Acute.EC50, Data.AggBySiteID.3a$SSDLOG10.Sigma.chronic.NOEC)

Data.AggBySiteID.3a$HQ.Acute = Data.AggBySiteID.3a$resultMaximumValue/Data.AggBySiteID.3a$HC50.Acute
Data.AggBySiteID.3a$HQ.Chronic = Data.AggBySiteID.3a$resultMeanValue/Data.AggBySiteID.3a$HC05.Chronic

```


Need to calculate "msPAF.Chronic.NOEC" and "msPAF.Acute.EC50"
- I think the assumption is that all chemicals have equal slope SSD to be able to compute the aggregated PAF

```{r}
summary(Data.SSD.1$X10LogSSDSlope.ug.L..SigmaAcute.EC50)
plot(hist(Data.SSD.1$X10LogSSDSlope.ug.L..SigmaAcute.EC50))
a <- (hist(Data.SSD.1$X10LogSSDSlope.ug.L..SigmaAcute.EC50,breaks = 100))
```

```{r}
which(is.na(Data.AggBySiteID.3a$HC50.Acute))[1]
ssdInfo[384,]
## note in this case X10LogSSDMedianConcentration.ug.L..MuAcute.EC50 = 0.93, but X10LogSSDSlope.ug.L..SigmaAcute.EC50 =NA
```


```{r}
# Summaries
summary(Data.AggBySiteID.3a$HQ.Acute)
summary(Data.AggBySiteID.3a$HQ.Chronic)

hist(log10(Data.AggBySiteID.3a$HQ.Acute))
hist(log10(Data.AggBySiteID.3a$HQ.Chronic))

#How many samples greater than HC05?
summary(Data.AggBySiteID.3a$HQ.Acute>1)
summary(Data.AggBySiteID.3a$HQ.Chronic>1)


# PAF by chemical ##################################################################################
# Calculate HU (Hazard Unit) Anti-log10 are taken on Mu because HUs needs to be calculated in log-non-tramsformed data.
Data.AggBySiteID.3a$HU.Acute.EC50 = Data.AggBySiteID.3a$resultMaximumValue/(10^Data.AggBySiteID.3a$SSDLOG10.Mu.Acute.EC50)
Data.AggBySiteID.3a$HU.Chronic.NOEC = Data.AggBySiteID.3a$resultMeanValue/(10^Data.AggBySiteID.3a$SSDLOG10.Mu.chronic.NOEC)
# Calculate PAF
Data.AggBySiteID.3a$PAF.Acute.EC50 = pnorm(log10(Data.AggBySiteID.3a$HU.Acute.EC50),0,Data.AggBySiteID.3a$SSDLOG10.Sigma.Acute.EC50,log=F) ## Note this is equal to pnorm(log10(Data.AggBySiteID.3a$resultMaximumValue),Data.AggBySiteID.3a$SSDLOG10.Mu.Acute.EC50 SSDLOG10.Sigma.Acute.EC50,)
# del <- Data.AggBySiteID.3a %>% mutate(PAF.Acute= pnorm(log10(resultMaximumValue),SSDLOG10.Mu.Acute.EC50,SSDLOG10.Sigma.Acute.EC50))
Data.AggBySiteID.3a$PAF.Chronic.NOEC = pnorm(log10(Data.AggBySiteID.3a$HU.Chronic.NOEC),0,Data.AggBySiteID.3a$SSDLOG10.Sigma.chronic.NOEC,log=F)

# Summaries
summary(Data.AggBySiteID.3a$PAF.Acute.EC50)
summary(Data.AggBySiteID.3a$PAF.Chronic.NOEC)

summary(Data.AggBySiteID.3a$PAF.Acute.EC50>0.05)
# Mode   FALSE    TRUE
# logical  243451    6495
6495/(6495+243451) #2% of samples ==>
# > summary(Data.AggBySiteID.3a$PAF.Acute.EC50>0.05)
# Mode   FALSE    TRUE
# logical  347934     882
# > 882/(882+347934)
# [1] 0.002528554

summary(Data.AggBySiteID.3a$PAF.Chronic.NOEC>0.05)
# Mode   FALSE    TRUE
# logical  225399   24547
24547/(24547+225399) #9.8 % of samples

hist(log10(Data.AggBySiteID.3a$PAF.Acute.EC50))
hist(log10(Data.AggBySiteID.3a$PAF.Chronic.NOEC))
```


```{r}
# Aggregate HU over all chemicals per station to compute MaxHQ, HI, HU, msPAF and maxPAF ##########################################################
HU.sum = aggregate(. ~ monitoringSiteIdentifier + Site.Year, data=Data.AggBySiteID.3a[,names(Data.AggBySiteID.3a)%in%c("monitoringSiteIdentifier","Site.Year","HU.Acute.EC50","HU.Chronic.NOEC", "HQ.Acute", "HQ.Chronic")], sum, na.rm=TRUE)
HQ.Max = aggregate(. ~ monitoringSiteIdentifier + Site.Year, data=Data.AggBySiteID.3a[,names(Data.AggBySiteID.3a)%in%c("monitoringSiteIdentifier","Site.Year","HU.Acute.EC50","HU.Chronic.NOEC","HQ.Acute", "HQ.Chronic", "PAF.Acute.EC50", "PAF.Chronic.NOEC")], max, na.rm=TRUE)

# summaries
summary(Data.AggBySiteID.3a$SSDLOG10.Sigma.Acute.EC50)
# Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
# 0.1500  0.7000  0.8200  0.8931  1.1100  2.4000
summary(Data.AggBySiteID.3a$SSDLOG10.Sigma.chronic.NOEC)
# Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
# 0.0000  0.7024  0.7799  0.8594  1.0202  2.1512

# Compute msPAF (multi-substance predicted affected fractions) Ismael's method
HU.sum$msPAF.Acute.EC50 = pnorm(log10(HU.sum$HU.Acute.EC50),0,mean(Data.AggBySiteID.3a$SSDLOG10.Sigma.Acute.EC50),log=F)
HU.sum$msPAF.Chronic.NOEC = pnorm(log10(HU.sum$HU.Chronic.NOEC),0,mean(Data.AggBySiteID.3a$SSDLOG10.Sigma.chronic.NOEC),log=F)

# Compute maxPAF (maximum PAF per site)
HQ.Max$maxPAF.Acute.EC50 = pnorm(log10(HQ.Max$HU.Acute.EC50),0,mean(Data.AggBySiteID.3a$SSDLOG10.Sigma.Acute.EC50),log=F)
HQ.Max$maxPAF.Chronic.NOEC = pnorm(log10(HQ.Max$HU.Chronic.NOEC),0,mean(Data.AggBySiteID.3a$SSDLOG10.Sigma.chronic.NOEC),log=F)

######################
# Zhenglei don't go further than here
names (HQ.Max)
# [1] "monitoringSiteIdentifier" "Site.Year"                "HQ.Acute"
# [4] "HQ.Chronic"               "HU.Acute.EC50"            "HU.Chronic.NOEC"
# [7] "PAF.Acute.EC50"           "PAF.Chronic.NOEC"         "maxPAF.Acute.EC50"
# [10] "maxPAF.Chronic.NOEC"
names (HU.sum)
# [1] "monitoringSiteIdentifier" "Site.Year"                "HQ.Acute"
# [4] "HQ.Chronic"               "HU.Acute.EC50"            "HU.Chronic.NOEC"
# [7] "msPAF.Acute.EC50"         "msPAF.Chronic.NOEC"

# I need you to check if the following calculations for computing are correct:
# "msPAF.Chronic.NOEC"
# "msPAF.Acute.EC50"
# I think the assumption is that all chemicals have equal slope SSD to be able to compute the aggregated PAF

# Further, I computed the maxPAF in two different ways (lines 697) aggregating over the dataset, and in line 713 and 714 (aggregating to maxHU, and computing maxPAF using the average slope).
# Results are quite different. I believe this points at an overstimation of msPAF when calculating it over many chemicals assuming equal SSD slope ~ 0.8
# "PAF.Acute.EC50"
# "maxPAF.Acute.EC50"
# "PAF.Chronic.NOEC"
# "maxPAF.Chronic.NOEC"


```


```{r}

HU.sum = aggregate(. ~ monitoringSiteIdentifier + Site.Year, data=Data.AggBySiteID.3a[,names(Data.AggBySiteID.3a)%in%c("monitoringSiteIdentifier","Site.Year","HU.Acute.EC50","HU.Chronic.NOEC", "HQ.Acute", "HQ.Chronic")], sum, na.rm=TRUE)
HQ.Max = aggregate(. ~ monitoringSiteIdentifier + Site.Year, data=Data.AggBySiteID.3a[,names(Data.AggBySiteID.3a)%in%c("monitoringSiteIdentifier","Site.Year","HU.Acute.EC50","HU.Chronic.NOEC","HQ.Acute", "HQ.Chronic", "PAF.Acute.EC50", "PAF.Chronic.NOEC")], max, na.rm=TRUE)

```


```{r}
Res <- Data.AggBySiteID.3a %>%  group_by(monitoringSiteIdentifier,phenomenonTimeReferenceYear,Site.Year) %>% summarise(HU_Sum_Acute=sum(HU.Acute.EC50,na.rm=T),HU_Sum_Chronic=sum(HU.Chronic.NOEC,na.rm=T),HQ_Sum_Acute=sum(HQ.Acute,na.rm=T),HQ_Sum_Chronic=sum(HQ.Chronic,na.rm=T),HU_Max_Acute=max(HU.Acute.EC50,na.rm=T),HU_Max_Chronic=max(HU.Chronic.NOEC,na.rm=T),HQ_Max_Acute=max(HQ.Acute,na.rm=T),HQ_Max_Chronic=max(HQ.Chronic,na.rm=T),PAF_Max_Acute=max(PAF.Acute.EC50,na.rm=T),PAF_Max_Chronic=max(PAF.Chronic.NOEC,na.rm=T)) ## Ratio
```

```{r}
Res <- Res %>% mutate(msPAF_Sum_Acute=pnorm(log10(HU_Sum_Acute),0,0.7),msPAF_Max_Acute=pnorm(log10(HU_Max_Acute),0,0.7),msPAF_Sum_Chronic=pnorm(log10(HU_Sum_Chronic),0,0.7),msPAF_Max_Chronic=pnorm(log10(HU_Max_Chronic),0,0.7)) 
```

```{r}
sum(Res$HU_Max_Acute>1,na.rm = T)/length(Res$HQ_Max_Acute)
sum(Res$HU_Max_Acute>0.1,na.rm = T)/length(Res$HQ_Max_Acute)


sum(Res$msPAF_Sum_Acute>0.05,na.rm = T)/length(Res$HQ_Max_Acute)
sum(Res$msPAF_Sum_Acute>0.1,na.rm = T)/length(Res$HQ_Max_Acute)

```

